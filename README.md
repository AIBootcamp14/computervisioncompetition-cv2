# Document Type Classification

ì´ í”„ë¡œì íŠ¸ëŠ” ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ ëŒ€íšŒ ì°¸ê°€ì— ì‚¬ìš©ëœ ì†”ë£¨ì…˜ìœ¼ë¡œ, ì»´í“¨í„° ë¹„ì „ ë”¥ëŸ¬ë‹ ê¸°ìˆ ë“¤ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¡°í•©í•˜ì—¬ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. 

íŠ¹íˆ, ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ê³  ìµœì¢… ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ëŒì–´ì˜¬ë¦¬ê¸° ìœ„í•œ ì•™ìƒë¸” ë° ìŠ¤íƒœí‚¹ ê¸°ë²•ì— ì¤‘ì ì„ ë‘ì–´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.

---

## 2ì¡° íŒ€ì› ì†Œê°œ

| ![ê¹€ì¥ì›](https://avatars.githubusercontent.com/u/128503571?v=4&s=200) | ![ê¹€ì˜](https://avatars.githubusercontent.com/u/213391898?v=4&s=200) | ![ë¯¼ë³‘í˜¸](https://avatars.githubusercontent.com/u/213389909?s=200&u=637057beaf59c03a304331ca2c5838c029195669&v=4) | ![ë¬¸ì±„ë¦°](https://avatars.githubusercontent.com/u/213385368?s=200&u=199e83da989abfc5387e2b64c00751a77bb5c6cc&v=4) | ![ì •ë¯¼ì§€](https://avatars.githubusercontent.com/u/208557619?v=4&s=100) |
| :--------------------------------------------------------------: | :--------------------------------------------------------------: | :--------------------------------------------------------------: | :--------------------------------------------------------------: | :--------------------------------------------------------------: |
|            ![GitHub](https://img.shields.io/badge/GitHub-ê¹€ì¥ì›ğŸ‘‘-181717?style=&logo=github&logoColor=white&link=https://github.com/jkim1209)             |            [![GitHub](https://img.shields.io/badge/GitHub-ê¹€ì˜-181717?style=flat&logo=github&logoColor=white)](https://github.com/kimyoung9689)            |            [![GitHub](https://img.shields.io/badge/GitHub-ë¯¼ë³‘í˜¸-181717?style=flat&logo=github&logoColor=white)](https://github.com/BH-Min-lab)            |            [![GitHub](https://img.shields.io/badge/GitHub-ë¬¸ì±„ë¦°-181717?style=flat&logo=github&logoColor=white)](https://github.com/CHAERINMOON)             |            [![GitHub](https://img.shields.io/badge/GitHub-ì •ë¯¼ì§€-181717?style=flat&logo=github&logoColor=white)](https://github.com/mingg210)          |
|                            íŒ€ì¥, ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ë§                             |                            ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ë§                             |                            ë°ì´í„° ì „ì²˜ë¦¬ ë° VLM                             |                            ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ë§                             |                            ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ë§                             |

## 0. Overview

ëª¨ë¸ ì•„í‚¤í…ì²˜: ë³¸ ì†”ë£¨ì…˜ì€ ViT ê¸°ë°˜ ì•„í‚¤í…ì²˜(vit_base_patch16_224)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ, í´ë˜ìŠ¤ë³„ ë§ì¶¤ ì¦ê°•Â·ë¶ˆê· í˜• ë³´ì •Â·2-Stage ì¶”ë¡ ì„ ê²°í•©í•´ Macro F1 ê¸°ì¤€ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

í•™ìŠµ ì „ëµ: í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì • + CosineAnnealingWarmup ìµœì í™” + Clean/Robust ê²€ì¦ + 2-Stage ë¼ìš°íŒ… ì¶”ë¡ 

ì†ì‹¤ í•¨ìˆ˜: Focal Loss with Class Balancing

ìµœì¢… ì ìˆ˜: Test Macro F1 Score 0.97 ë‹¬ì„±

í™˜ê²½: 
![Python](https://img.shields.io/badge/Python-3776AB?style=plastic&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=plastic&logo=pytorch&logoColor=white)
![Torchvision](https://img.shields.io/badge/Torchvision-EE4C2C?style=plastic&logo=pytorch&logoColor=white)
![timm](https://img.shields.io/badge/timm-EE4C2C?style=plastic&logo=pytorch&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=plastic&logo=scikitlearn&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=plastic&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-0B5FFF?style=plastic&logo=numpy&logoColor=white)
![Albumentations](https://img.shields.io/badge/Albumentations-FF6F00?style=plastic)
![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=plastic&logo=opencv&logoColor=white)
![W&B](https://img.shields.io/badge/Weights%20%26%20Biases-FFBE00?style=plastic&logo=weightsandbiases&logoColor=black)


### Environment

- OS: Ubuntu 20.04.6 LTS (tested)  
- Python: 3.10  
- PyTorch: 2.1.0  
- CUDA: 11.8, cuDNN 8.7  
- GPU: NVIDIA GeForce RTX 3090 (24GB VRAM)  
- Dependencies: See [environment.yml](./environment.yml)

### Requirements

- python=3.10
- pytorch=2.1.0
- pytorch-cuda=11.8
- torchvision=0.16.0
- torchaudio=2.1.0
- numpy=1.26
- scipy=1.11
- scikit-learn=1.3
- pandas=2.1

---

## 1. Competiton Info

### Overview

ì´ ëŒ€íšŒëŠ” ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ ëŒ€íšŒë¡œ, ê¸ˆìœµ, ì˜ë£Œ, ë³´í—˜, ë¬¼ë¥˜ ë“± ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ í™œìš©ë˜ëŠ” ë¬¸ì„œ ì´ë¯¸ì§€ë¥¼ 17ê°œ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. í˜„ì—… ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œì‘ë˜ì–´ ì‹¤ì œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.

- **ê¸°ê°„**: 2025ë…„ 9ì›” 1ì¼ ~ 2025ë…„ 9ì›” 11ì¼

- **ì£¼ì œ**: ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜

- **í‰ê°€ì§€í‘œ**: Macro F1 Score

$$
\text{Macro-F1} = \frac{1}{N} \sum_{i=1}^{N} F1_i
$$

$$
F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
$$

 > - $N$: í´ë˜ìŠ¤ ê°œìˆ˜ (ì´ë²ˆ ëŒ€íšŒì˜ ê²½ìš° 17)  
 > - $F1_i$: ië²ˆì§¸ í´ë˜ìŠ¤ì˜ F1 Score  
 > - Precision = $\frac{TP}{TP + FP}$  
 > - Recall = $\frac{TP}{TP + FN}$  
 > - TP: True Positive, FP: False Positive, FN: False Negative  

- **ì£¼ìš” ëª©í‘œ**:
  - **ë‹¤ì–‘í•œ CNN ê¸°ë°˜ Backbone (ResNet, EfficientNet ë“±)** ë° ìµœì‹  ê¸°ë²•ì„ ì ìš© ë° ì„±ëŠ¥ ë¹„êµ  
  - **ë°ì´í„° ë¶ˆê· í˜• ë¬¸ì œë¥¼ ê³ ë ¤í•œ í•™ìŠµ ê¸°ë²• ì‹¤í—˜**(ë°ì´í„° ì¦ê°•, í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© ë“±) ì‹¤í—˜  
  - **Macro-F1 ê¸°ì¤€ ìµœì  ì„±ëŠ¥ ë‹¬ì„±**ì„ ëª©í‘œë¡œ í•˜ëŠ” ëª¨ë¸ êµ¬ì¶•

---

## 2. Components

### Directory

í”„ë¡œì íŠ¸ëŠ” ëª¨ë“ˆì„±ê³¼ ì¬ì‚¬ìš©ì„±ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ëª…í™•í•œ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ë”°ë¦…ë‹ˆë‹¤.


```txt
.
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ noisy               # src/data/EDA_mismatch.py ë¡œ í™•ì¸í•œ ì˜ëª» ì˜ˆì¸¡í•œ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥
â”‚Â Â  â”œâ”€â”€ test                # test ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥
â”‚Â Â  â””â”€â”€ train               # train ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥
â”œâ”€â”€ img                     # EDA ê²°ê³¼ ë° í•„ìš”í•œ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥
â”œâ”€â”€ logs                    # run_scripts ë°°ì‰¬ íŒŒì¼ ì‹¤í–‰ ë¡œê·¸ ì €ì¥
â”œâ”€â”€ model                   # ê° ëª¨ë¸ ë””ë ‰í† ë¦¬ ì•ˆì— foldë³„ .pt íŒŒì¼ ë° train_summary.json ì €ì¥
â”‚Â Â  â”œâ”€â”€ convnext_base.fb_in22k_ft_in1k_384_auto     
â”‚Â Â  â”œâ”€â”€ efficientnet_b4.ra2_in1k_auto
â”‚Â Â  â”œâ”€â”€ maxvit_base_tf_512.in21k_ft_in1k_auto
â”‚Â Â  â”œâ”€â”€ tf_efficientnet_b7.ap_in1k_auto
â”‚Â Â  â”œâ”€â”€ vit_base_patch14_dinov2.lvd142m_auto
â”‚Â Â  â”œâ”€â”€ vit_base_patch16_siglip_512.webli_auto
â”‚Â Â  â””â”€â”€ ...
â”œâ”€â”€ output                  # ê²°ê³¼ë¬¼ .csv íŒŒì¼ ì €ì¥
â”‚Â Â  â””â”€â”€ oof                 # OOF .csv íŒŒì¼ ì €ì¥
â”œâ”€â”€ run_scripts             # ì‹¤í–‰ ëª…ë ¹ì–´ .sh íŒŒì¼ ì €ì¥
â”œâ”€â”€ src                     # ìŠ¤í¬ë¦½íŠ¸ .py íŒŒì¼ ì €ì¥
â”‚   â”œâ”€â”€ data
â”‚   â”‚Â Â  â”œâ”€â”€ EDA.py
â”‚   â”‚Â Â  â”œâ”€â”€ EDA_mismatch.py
â”‚   â”‚Â Â  â”œâ”€â”€ dataset.py
â”‚   â”‚Â Â  â””â”€â”€ transform.py
â”‚   â”œâ”€â”€ ensemble.py
â”‚   â”œâ”€â”€ evaluate
â”‚   â”‚Â Â  â”œâ”€â”€ evaluate.py
â”‚   â”‚Â Â  â””â”€â”€ identify_possible_mislabeled_data.py
â”‚   â”œâ”€â”€ inference
â”‚   â”‚Â Â  â””â”€â”€ inference.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ output_to_submission.py
â”‚   â””â”€â”€ train
â”‚       â”œâ”€â”€ correct_minor_classes.py
â”‚       â”œâ”€â”€ schedulers.py
â”‚       â””â”€â”€ train.py
â””â”€â”€ wandb                   # wandb íŒŒì¼ ì €ì¥
    â”œâ”€â”€ latest-run
    â””â”€â”€ ...
```

---

## 3. Data descrption

### Dataset overview

- ì´ë²ˆ ëŒ€íšŒ ë°ì´í„°ëŠ” ê¸ˆìœµ, ì˜ë£Œ, ë¬¼ë¥˜ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì‹¤ì œ ë¬¸ì„œ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, ì´ 17ê°œì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤. í•™ìŠµ ë°ì´í„° 1,570ì¥, í‰ê°€ ë°ì´í„° 3,140ì¥ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### EDA

- í´ë˜ìŠ¤ ë¶ˆê· í˜•: íŠ¹ì • í´ë˜ìŠ¤(1, 13, 14)ì˜ ë°ì´í„° ìˆ˜ê°€ ë§¤ìš° ì ì€ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.
<p align="center">
  <img src="https://github.com/user-attachments/assets/e7edfab1-fc04-4095-968e-ad244837f789" 
       alt="train_distribution_by_class" width="700" height="350">
</p>

- ì´ë¯¸ì§€ í•´ìƒë„: ì´ë¯¸ì§€ í¬ê¸°ëŠ” 512pxì—ì„œ 763pxê¹Œì§€ ë‹¤ì–‘í•˜ê²Œ ë¶„í¬ë˜ì–´ ìˆìŒì„ íŒŒì•…í–ˆìŠµë‹ˆë‹¤.
<p align="center">
  <img src="https://github.com/user-attachments/assets/577bf222-6aa8-47af-8c41-b10400fdfa0c" alt="train_img_size" width="49%">
  <img src="https://github.com/user-attachments/assets/b006d23f-5658-4fed-bac7-7390ea68307e" alt="test_img_size" width="49%">
</p>


- ë ˆì´ë¸” ì •í™•ë„: í•™ìŠµ ë°ì´í„° ì¤‘ ì¼ë¶€ ì˜¤ë¶„ë¥˜ëœ ì´ë¯¸ì§€ë“¤ì´ ì¡´ì¬í•˜ì—¬, ë°ì´í„° ë ˆì´ë¸”ì— íœ´ë¨¼ ì—ëŸ¬ê°€ ì¼ë¶€ ë°œê²¬ë˜ì–´ ìˆ˜ì •í•˜ì˜€ìŠµë‹ˆë‹¤.
<p align="center">
  <img src="https://github.com/user-attachments/assets/47664421-d61e-4bc6-8b99-fbb5c1043c85" width="29%">
  <img src="https://github.com/user-attachments/assets/319c3161-a0e8-4582-9513-5fb0fd520a4b" width="33%">
  <img src="https://github.com/user-attachments/assets/edb79c24-b8e2-4123-9dea-cb5cc36813d1" width="33%">
</p>

### Data Processing

ì „ì²˜ë¦¬: ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì˜ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆí•˜ê³ , RGB ì±„ë„ë³„ë¡œ í‰ê·  ë° í‘œì¤€ í¸ì°¨ë¥¼ ì‚¬ìš©í•´ ì •ê·œí™”í–ˆìŠµë‹ˆë‹¤.

- **ë°ì´í„° ì¦ê°• (í´ë˜ìŠ¤ë³„ íŒŒì´í”„ë¼ì¸)**  
  - ë¬¸ì„œë¥˜(DOC), ì‹ ë¶„ì¦/ì—¬ê¶Œ(ID_CERT), ì°¨ëŸ‰(CAR) ì„¸ ì§‘í•©ìœ¼ë¡œ ë¶„ë¦¬.  
  - ë¬¸ì„œë¥˜ëŠ” OverlayFromPool ê¸°ë°˜ **self/pool í˜¼í•© overlay** ì¶”ê°€.  
  - ì†Œìˆ˜ í´ë˜ìŠ¤ëŠ” heavy transform í™•ë¥ ì  ì ìš©.
 
 #### ì´ë¯¸ì§€ ì¦ê°• íŒŒì´í”„ë¼ì¸

| í´ë˜ìŠ¤ | Base Transform | Heavy Transform | ì¶”ê°€ íŠ¹ì§• |
|--------|----------------|-----------------|-----------|
| ë¬¸ì„œë¥˜(DOC) | Affine, Rotate90, HueSatShift, CLAHE, Downscale, Noise | ë” ê°•í•œ Affine/Noise, OverlayFromPool(base/heavy) | Document ì „ìš© Overlay ì¶”ê°€ |
| ì‹ ë¶„ì¦/ì—¬ê¶Œ(ID) | Affine, ColorJitter, Noise (ì¤‘ê°„ ê°•ë„) | ì¼ë¶€ heavy | OCR-like ì†ìƒ |
| ì°¨ëŸ‰(CAR) | Affine, Contrast, Blur, Noise | ì¼ë¶€ heavy | ë°˜ì‚¬/ë…¸ì´ì¦ˆ ê°•í™” |

---

## 4. Modeling

### Model description

- **ëª¨ë¸ & ì…ë ¥ í¬ê¸° ìë™í™”**  
  - `timm` ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì‚¬ìš©. ì…ë ¥ í¬ê¸°ëŠ” `"auto"`, `"auto-long"`, ì •ìˆ˜ ì§€ì • ê°€ëŠ¥.  
  - ì§€ì› ëª¨ë¸ ì˜ˆì‹œ: ConvNeXt, EfficientNet, MaxViT, ViT(DINOv2, SigLIP) ë“±.

- **ë°ì´í„° ë¶„í•  & ì¬í˜„ì„±**  
  - `StratifiedKFold(n_splits=5, shuffle=True, random_state=42)` ì‚¬ìš©.  
  - ì‹œë“œ ê³ ì • ë° torchÂ·numpyÂ·cudnnì˜ deterministic ëª¨ë“œ ì ìš©.

- **ë°ì´í„° ì¦ê°• (í´ë˜ìŠ¤ë³„ íŒŒì´í”„ë¼ì¸)**  
  - ë¬¸ì„œë¥˜(DOC), ì‹ ë¶„ì¦/ì—¬ê¶Œ(ID_CERT), ì°¨ëŸ‰(CAR) ì„¸ ì§‘í•©ìœ¼ë¡œ ë¶„ë¦¬.  
  - ë¬¸ì„œë¥˜ëŠ” OverlayFromPool ê¸°ë°˜ **self/pool í˜¼í•© overlay** ì¶”ê°€.  
  - ì†Œìˆ˜ í´ë˜ìŠ¤ëŠ” heavy transform í™•ë¥ ì  ì ìš©.

- **ì†ì‹¤í•¨ìˆ˜ & ìµœì í™”**  
  - ê¸°ë³¸: LabelSmoothingCE  
  - ì˜µì…˜: FocalLoss(Î³=1.5~2.0, class-balanced weight ì§€ì›).  
  - Mixed Precision, Accumulation, Gradient Clipping, EMA ì ìš©.  
  - ìŠ¤ì¼€ì¤„ëŸ¬: CosineAnnealingWarmupRestarts ì ìš©.

- **Early Stopping & ì²´í¬í¬ì¸íŠ¸**  
  - `es_mode={loss|f1|both|either}`, patience=10, Î”loss=0.001, Î”f1=0.0005.  
  - foldë³„ `*_best_loss.pt`, `*_best_f1.pt` ì €ì¥.

- **ê²€ì¦ ì²´ê³„ (Validation)**  
  - clean valid + robust valid (ë…¸ì´ì¦ˆ, ì••ì¶•, ë‹¤ìš´ìŠ¤ì¼€ì¼ ìºì‹œ ê³ ì •).  
  - robust ê²€ì¦ì€ ì‹¤ì„¸ê³„ ì„±ëŠ¥ ê·¼ì ‘ ëª¨ë‹ˆí„°ë§ ì§€í‘œë¡œ ì‚¬ìš©.

- **ì¶”ë¡  (Inference)**  
  - Fold ì•™ìƒë¸” í‰ê· (logit or prob).  
  - TTA ì§€ì›(Flip, 90/180/270 íšŒì „).  
  - Stage-2 ë¼ìš°íŒ…: ë¶ˆí™•ì‹¤ ìƒ˜í”Œë§Œ `doc_restore_bal` ë˜ëŠ” `doc_restore_max` presetìœ¼ë¡œ ì¬ì¶”ë¡ .

- **ìŠ¤íƒœí‚¹ ì•™ìƒë¸” (Ensemble)**  
  - ë‹¤ì¤‘ ëª¨ë¸ OOF/Test í™•ë¥  â†’ Logistic Regression meta-model.  
  - Feature ëª¨ë“œ: `proba`, `logproba`, `both`. ë‚´ë¶€ CVë¡œ `C` ì„ íƒ, ì§€í‘œ=macro F1.

#### ì•„í‚¤í…ì²˜ & í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ì˜ˆì‹œ

| ëª¨ë¸ ì•„í‚¤í…ì²˜ | ì…ë ¥ í¬ê¸° | Epochs | Effective Batch Size | LR (max) | ìŠ¤ì¼€ì¤„ëŸ¬ | ì†ì‹¤í•¨ìˆ˜ |
|---------------|-----------|--------|------------|-----------|----------|-----------|
| ConvNeXt-B    | auto(384) | 150    | 32         | 3e-4      | CosineAnnealingWarmupRestarts | LabelSmoothingCE |
| EfficientNet-B4 | 512     | 150     | 32         | 3e-4      | ë™ì¼     | LabelSmoothingCE |
| MaxViT-B      | auto(512)       | 150     | 32         | 1e-4      | ë™ì¼     | Focal |
| ViT-B SigLIP  | auto(512)       | 150     | 32         | 7e-5      | ë™ì¼     | Focal |
| ViT-B DINOv2  | auto(518)   | 150     | 32         | 5e-5      | ë™ì¼     | Focal|


#### 2ë‹¨ê³„ ë¼ìš°íŒ… ì¶”ë¡  ë‹¤ì´ì–´ê·¸ë¨
```mermaid
flowchart TD
    A["Stage-1 Inference<br/>(Fold Ensemble + TTA)"] --> B{Route Decision}
    B -->|í™•ì‹¤| C["Final Prediction<br/>(Use Stage-1 prob)"]
    B -->|ë¶ˆí™•ì‹¤| D["Stage-2 Inference<br/>(Preset: doc_restore_bal/max)"]
    D --> E["Blend Stage-1 & Stage-2 Proba<br/>(0 &le; blend &le; 1)"]
    E --> F["Final Prediction"]
```

| í•­ëª© | ì„¤ëª… |
|------|------|
| Routing ê¸°ì¤€ | entropy / margin / sum / pred |
| Gate | default = 0.60, Stage-2 ìƒ˜í”Œ ìˆ˜ ì œí•œ(`stage2_limit`) ê°€ëŠ¥ |
| Blend | 1.0 = Stage-2ë§Œ, 0.5 = ë™ë“± ë¸”ë Œë“œ, 0 = Stage-1 ìœ ì§€ |

---

## 5. Result

### Leader Board

* ![Rank 1](https://img.shields.io/badge/Leaderboard-Rank%201-gold)
* ![Macro F1 0.9692](https://img.shields.io/badge/Macro%20F1-0.9692-blue)

<img width="972" height="262" alt="image" src="https://github.com/user-attachments/assets/89bfc83f-8806-466e-9bc5-709db05eea26" />

### ëª¨ë¸ í•™ìŠµ ê²°ê³¼ ìš”ì•½

* ì‚¬ìš©í•œ ëª¨ë¸: ViT-B-16-SigLIP (ë‹¨ì¼ëª¨ë¸)

* Confusion matrix
<p align="center">
  <img src="https://github.com/user-attachments/assets/3ab42ea2-bdad-46d4-8cc3-e4493c43e562" alt="confusion_matrix_table_white" width="800" height="800">
</p>

* Learning Curve
</p>
<p align="center">
  <img src="https://github.com/user-attachments/assets/cd96cc86-f832-47ea-85a7-721ab9af5fd6" alt="learning_rate" width="700">
</p>

* Training loss/f1
<p align="center">
  <img src="https://github.com/user-attachments/assets/d5c56e59-7e71-48b7-a797-6fc2c1afaef2" alt="train_loss" width="49%">
  <img src="https://github.com/user-attachments/assets/e3d1dd99-44bf-403b-aaf8-2b1ad4dbfe0d" alt="train_f1" width="49%">
</p>

* Validation loss/f1 (Clean) 
<p align="center">
  <img src="https://github.com/user-attachments/assets/a792f4b4-fef8-45cf-9af8-068f3a9cfd53" alt="clean_valid_loss" width="49%">
  <img src="https://github.com/user-attachments/assets/97dba926-d6bf-45c9-8ad1-d50b81161109" alt="clean_valid_f1" width="49%">
</p>

* Validation loss/f1 (Robust)
<p align="center">
  <img src="https://github.com/user-attachments/assets/37e32746-ce48-4218-a2eb-b7677541d901" alt="robust_valid_loss" width="49%">
  <img src="https://github.com/user-attachments/assets/ea94f40d-d814-4332-b66b-c4b60b4878e4" alt="robust_valid_f1" width="49%">


### Presentation

- [Google Slides](https://docs.google.com/presentation/d/10o12igXX3xXg1zpI-M4KdHMrxI4OToEL/edit?slide=id.p5#slide=id.p5)

---

## 6. How to Run 

### Setup

#### 1. í™˜ê²½ ì„¤ì •

```bash
# (í•„ìš” ì‹œ) Conda í™˜ê²½ ìƒì„±
conda env create -f environment.yml
conda activate <your-env>
```

#### 2. í•™ìŠµ ë° ì¶”ë¡  ì‹¤í–‰
src.mainìœ¼ë¡œ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. (--do_inferë¥¼ ì£¼ë©´ í•™ìŠµ ì§í›„ ì¶”ë¡ ê¹Œì§€ ìˆ˜í–‰)

ì˜ˆì‹œ)

```bash
python -m src.main \
  --arch resnetrs50.tf_in1k \
  --img_size auto \
  --n_folds 5 --epochs 70 --batch_size 32 \
  --lr 3e-4 --accum_steps 2 --use_ema \
  --eval_mode f1 --es_mode either --patience 10 \
  --use_focal --focal_gamma 1.8 --focal_weight alpha_cb \
  --use_logit_adjustment --logit_tau 1.0 \
  --save_oof_folds --save_fold_logs \
  --do_infer --save_proba --tta --avg logit
```

í•µì‹¬ ì˜µì…˜ ìš”ì•½:
* --img_size auto: ëª¨ë¸ ê¸°ë³¸ ê¶Œì¥ í•´ìƒë„ì— ë§ì¶¤  
* --n_folds 5: 5-Fold CV  
* --use_focal/--use_logit_adjustment: í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •(ì˜µì…˜)  
* --es_mode either: Loss ë˜ëŠ” F1 ê°œì„  ì¤‘ í•˜ë‚˜ë©´ ê³„ì†, ëª¨ë‘ ì•…í™” ì‹œ ì¡°ê¸°ì¢…ë£Œ(early stopping)   
* --do_infer: í•™ìŠµ í›„ 1-Stage ì¶”ë¡ (TTA/ì•™ìƒë¸” í¬í•¨)

#### 3. ì¶”ë¡ ë§Œ ë”°ë¡œ ì‹¤í–‰ (íŠ¹íˆ 2-stage ì¶”ë¡ ì„ ì´ìš©í•˜ì—¬ ë‹¤ì–‘í•˜ê²Œ ë¹„êµí•˜ê³  ì‹¶ì€ ê²½ìš°)

ì˜ˆì‹œ)

```bash
python -m src.inference.inference \
  --arch resnetrs50.tf_in1k \
  --img_size auto \
  --summary_path model/resnetrs50.tf_in1k_auto/train_summary.json \
  --test_dir data/test --output_dir output \
  --avg prob --infer_batch_size 64 --num_workers 8 --tta --save_proba \
  --stage1_presets "none,doc_deskew" \
  --stage2_preset doc_restore_max \
  --stage2_mode sum --route_classes "3,7,11" \
  --route_gate 0.65 \
  --stage2_blend 0.85 \
  --out_tag "2-stage"
```

í•µì‹¬ ì˜µì…˜ ìš”ì•½:
* Stage-1: ê¸°ë³¸ ì¶”ë¡ (TTA/í´ë“œ í‰ê· ) â†’ ë¶ˆí™•ì‹¤ ìƒ˜í”Œë§Œ ì„ ë³„
* Stage-2: ë³µì› ê°•í™” preset(doc_restore_max)ë¡œ ì¬ì¶”ë¡  í›„ Stage-1ê³¼ ë¸”ë Œë”©
* --route_classes "3,7,11": ì§€ì • í´ë˜ìŠ¤ë§Œ ë¼ìš°íŒ…
* --route_gate 0.65: ë¼ìš°íŒ… ì„ê³„ê°’
* --stage2_blend 0.85: Stage-2 ë¹„ì¤‘(0~1)


#### 4. ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±
ì¶”ë¡  ê²°ê³¼ë¥¼ ëŒ€íšŒ ì œì¶œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```bash
python -m src.output_to_submission
```
ê¸°ë³¸ ë™ì‘: output/*.csv â†’ output/submission/ì— ID,target í˜•ì‹ìœ¼ë¡œ ì €ì¥(ì¤‘ë³µ ì‹œ ìë™ ë„˜ë²„ë§)

#### 5. (ì„ íƒ) ìŠ¤íƒœí‚¹ ì•™ìƒë¸”
ìµœì¢… ì œì¶œì€ ë‹¨ì¼ ëª¨ë¸ì„ ì‚¬ìš©í–ˆì§€ë§Œ, í•„ìš” ì‹œ OOF/Test í™•ë¥ ì„ ì´ìš©í•´ ë¡œì§€ìŠ¤í‹± íšŒê·€ ë©”íƒ€ëª¨ë¸ë¡œ ìŠ¤íƒœí‚¹ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì˜ˆì‹œ)
```bash
python -m src.ensemble \
  --oof  output/oof/resnetrs50.tf_in1k_auto_oof.csv \
        output/oof/vgg16_bn.tv_in1k_auto_oof.csv \
  --test output/resnetrs50.tf_in1k_auto_2-stage.csv \
        output/vgg16_bn.tv_in1k_auto_2-stage.csv \
  --feature both --standardize \
  --cv_k 10 --C_grid 0.01 0.03 0.05 0.07 0.1 0.25 0.5 1.0 2.0 4.0 --max_iter 5000 \
  --target_csv data/sample_submission.csv --also_geomean
```
í•µì‹¬ ì˜µì…˜ ìš”ì•½:
* --oof: í•™ìŠµ ê³¼ì •ì—ì„œ ìƒì„±ëœ ê° ëª¨ë¸ì˜ OOF(out-of-fold) ì˜ˆì¸¡ CSV íŒŒì¼ ê²½ë¡œ
* --test: ëŒ€ì‘ë˜ëŠ” ê° ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ CSV íŒŒì¼ ê²½ë¡œ
* --feature both: ìŠ¤íƒœí‚¹ ì…ë ¥ íŠ¹ì§•ìœ¼ë¡œ í™•ë¥ ê°’(proba)ê³¼ ë¡œê·¸ í™•ë¥ ê°’(log-proba) ëª¨ë‘ ì‚¬ìš©
* --cv_k 10: ë©”íƒ€ëª¨ë¸ í•™ìŠµ ì‹œ ë‚´ë¶€ êµì°¨ê²€ì¦ fold ìˆ˜ (10-Fold CV)
* --C_grid: ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ ê·œì œ ê°•ë„ Cì— ëŒ€í•´ íƒìƒ‰í•  í›„ë³´ ê°’ ë¦¬ìŠ¤íŠ¸
* --max_iter 5000: ë¡œì§€ìŠ¤í‹± íšŒê·€ ìµœëŒ€ ë°˜ë³µ ìˆ˜ (ìˆ˜ë ´ ì•ˆì •ì„± í™•ë³´)
* --target_csv: ìµœì¢… ì œì¶œ í˜•ì‹(ì˜ˆ: sample_submission.csv)ì„ ì°¸ê³ í•˜ì—¬ ì¶œë ¥ ì»¬ëŸ¼ ë§ì¶¤
* --also_geomean: ë©”íƒ€ëª¨ë¸ ê²°ê³¼ ì™¸ì— ë‹¨ìˆœ ê¸°í•˜í‰ê· (geometric mean) ì•™ìƒë¸” ê²°ê³¼ë„ í•¨ê»˜ ìƒì„±

---

## ETC

### Meeting Log

- ë³¸ í”„ë¡œì íŠ¸ ì§„í–‰ ê³¼ì •ì—ì„œ ì‘ì„±ëœ íšŒì˜ ê¸°ë¡ ë° ì‹¤í—˜ ë¡œê·¸ëŠ” ì´ ë ˆí¬ì§€í† ë¦¬ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

### Reference

- [Stages.ai](https://stages.ai/en) â€” ë³¸ ëŒ€íšŒ í”Œë«í¼  
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)  
- [timm (PyTorch Image Models)](https://github.com/huggingface/pytorch-image-models)  
- [Albumentations](https://github.com/albumentations-team/albumentations)  
- [scikit-learn Documentation](https://scikit-learn.org/stable/documentation.html)  
- [OpenCV](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html)  
- [Vision Transformer (ViT) paper](https://arxiv.org/abs/2010.11929)  
- [MaxViT paper](https://arxiv.org/abs/2204.01697)  
- [ConvNeXt paper](https://arxiv.org/abs/2201.03545)  
- [EfficientNet paper](https://arxiv.org/abs/1905.11946)  
- [DINOv2 paper](https://arxiv.org/abs/2304.07193)  
- [SigLIP paper](https://arxiv.org/abs/2303.15343)  
- [Weights & Biases (W&B)](https://docs.wandb.ai/)  

### Acknowledgement
ë³¸ í”„ë¡œì íŠ¸ëŠ” Upstage AI Lab 14ê¸° êµìœ¡ ê³¼ì •ì˜ ì¼í™˜ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìœ¼ë©°, íŒ€ì›ë“¤ì˜ í˜‘ì—…ê³¼ í”¼ë“œë°±ì„ í†µí•´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

---
